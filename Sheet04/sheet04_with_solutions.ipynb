{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Computer Vision (Winter Term 2022/23) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b1c9d7364139283",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 04: Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f36caad6a99f515",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, December 4th, 2022**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-exp",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (the exponential function) [0 Points]\n",
    "\n",
    "This exercise is supposed to be basic (but maybe less familiar than the last one), does not give any points, and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up (again). You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-exp-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is an *exponential function*? How can it be characterized? What is special about $e^x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-exp-a1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "An exponential function is a function in which a constant is raised to power of a variable like $\\mathrm{f}(x) = \\mathrm{a}^x$.\n",
    "In the case that the constant is Euler's number $e$ it holds that the derivative of the function the function itself $\\frac{\\mathrm{d}}{\\mathrm{d} x} \\mathrm{e}^x = \\mathrm{e}^x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-exp-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** How is the exponential function defined for complex arguments? In what way(s) does this generalize the real case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-exp-a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "$e^z = e^{x + iy} = e^x\\cdot e^{iy} = e^x \\cdot(\\cos(y) + i\\sin(y))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-exp-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** The complex exponential function allows to define a mapping $\\mathbb{R}\\to\\mathbb{C}$ by $x\\mapsto e^{ix}$? How does the graph of this mapping look like? Where are the points $e^{2\\pi i\\frac mn}$ for $m=0,...,n\\in\\mathbb{N}$ located on this graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-exp-a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The graph is the unit circle in the complex plane. The function is periodic with period length $2\\pi$, with $e^{i0} = 1$. The points $e^{2\\pi i\\frac mn}$ are dividing the circle into $n$ equal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-exp-a3b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x = np.linspace(-3*np.pi,3*np.pi,200)\n",
    "z = np.exp(1j*x)\n",
    "\n",
    "# computing points 2*pi*m/n\n",
    "n = 7\n",
    "points = np.linspace(0, 2*np.pi, n, endpoint=False)\n",
    "z_points = np.exp(1j*points)\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "ax1 = plt.subplot(1,2,1);\n",
    "ax1.plot(np.real(z), np.imag(z))\n",
    "ax1.plot(np.real(z_points), np.imag(z_points), 'r*')\n",
    "ax1.set_xlabel('$\\Re(e^{ix})$')\n",
    "ax1.set_ylabel('$\\Im(e^{ix})$')\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot(x,0*x,'r') # the input line\n",
    "ax2.plot(x,np.real(z),np.imag(z))\n",
    "ax2.plot(points,np.real(z_points), np.imag(z_points), 'r*')\n",
    "ax2.set_xlabel('X axis')\n",
    "ax2.set_ylabel('$\\Re(e^{ix})$')\n",
    "ax2.set_zlabel('$\\Im(e^{ix})$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "color-header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment 1: Color perception and color spaces (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "color-ex-a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Human color perception\n",
    "\n",
    "Explain how human color perception works, that is, how light of different frequencies (and mixtures of different frequencies) is perceived as different colors.\n",
    "Then discuss what light sources/frequencies could be used to induce the perception of the following colors?\n",
    "* orange\n",
    "* brown\n",
    "* purple\n",
    "* white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "color-ex-answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The human vision system builds on specialized retinal cells known as cone cells. These cells usually contain three different forms of pigment proteins that have different spectral sensitivities (S=short with highest response for ligth with wavelength around 440 nm, M=medium , L=long). Color perception evolves by evaluating the different activations of these cells. Each monochromatic light source (emitting light of a fixed frequency) results in a specific combination of activations of these three types of cones and hence a specific color perception. The same perception can also be caused by a combination of different light sources that result in the same stimulation of cones.  There are also combined stimulations of cones that can not be caused by monochromatic lights but only by mixed lights, like pink (e.g. as a combination of purple and red, mainly activating S and L cones) or white (stimulation of all three types of cones).\n",
    "\n",
    "* orange can be obtained by monochromatic light with wavelengths around 620 nm, activating the L cones significantly more than the M cones, leaving the S cones off. Any mix of light frequencies resulting in the same activation pattern will also be perceived as orange.\n",
    "* brown: brown arises from the same activation patterns as orange, just with lower intensities. Hence brown is just a dark orange.\n",
    "* purple: purple light has a relatively short wavelength around 400 nm, mainly stimulating the S cones.\n",
    "* white: perception of white is caused by simultanous activation of all three types of cones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-958e377d81eb0d09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### b) Additive and subtractive color mixing\n",
    "\n",
    "Explain the ideas of additive and subtractive color mixing. Name examples for each mixing model and describe technical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-624f75866a0864a2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "In additive color mixing the colors are made of coincident component lights. An example for additive color mixing is the RGB model. Additive color mixing is useful for describing situations where colors are created by mixing light sources with different wavelength, like computer screens or projectors. \n",
    "\n",
    "Subtractive color mixing describes the generation of color by removing color components from the white base color. An example is the CMY model. Subtractive color mixing apply to situations like printing and painting, where applying and mixing different inks results in the desired colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a670a13b8a3e0a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### c) RGB and HSV color space\n",
    "\n",
    "Compare the RGB and the HSV color spaces. Name advantages and discuss suitable applications for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d36c12e0dfa2d281",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The RGB color space describes colors as a combination of red, green, and blue components. Geometrically this color space can be described as a cube, with the three base colors spanning the three spatial dimensions.\n",
    "The RGB space is useful for devices that create output by mixing red, green, and blue light sources.\n",
    "\n",
    "The HSV color space describes colors bye their hue, saturation, and value (brightness). The hue values are assumed to have a cyclic structure, and all colors with a value of 0 are the same (black), resulting in a cone shape for that color space. The HSV space is useful when processing images with a focus on color, independent of brightness (light and shadow) and/or saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "seg-hist",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: Histogram-based segmentation (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "seg-hist-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Histogram-based segmentation\n",
    "\n",
    "What is histogram-based segmentation? What are it's goals, benefits, and problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "seg-hist-a1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "In histogram-based segmentation one tries to determine a good threshold value to separate the image foreground from the background. If the histogram shows, that the gray values can be clearly split into a light and a dark part, the process is straight-forward. Otherwise more sophisticated methods have to be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "seg-hist-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Threshold computation\n",
    "\n",
    "There exist different methods to automatically determine a threshold for an image. Find at least two that are provided by scikit-image and describe them in more detail. Then apply them to the images `schrift.png` and `pebbles.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "seg-hist-a2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "* Otsu's method minimizes the intra-class variance, i.e. the variance in the class of pixels $F$ that are considered\n",
    "  to be foreground and the variance of the pixels $B$ considered background. This is equivalent to maximize the\n",
    "  inter-class variance. (`skimage.filters.threshold_otsu`)\n",
    "* The minimum method: The histogram of the input image is computed and smoothed until there are only two maxima.\n",
    "  Then the minimum in between is the threshold value. (`skimage.filters.threshold_minimum`)\n",
    "* Simply use the mean of the grayscale values an a threshold (`skimage.filters.threshold_mean`)\n",
    "\n",
    "There exist many more, e.g. the Ridler-Calvard method (`skimage.filters.threshold_isodata`), Li's Minimum Cross Entropy method (`skimage.filters.threshold_li`), ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "seg-hist-code",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get an impression of how the histograms look\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "img1 = imread('images/schrift.png')\n",
    "img2 = imread('images/pebbles.jpg') \n",
    "\n",
    "plt.figure(figsize=(15, 10)) \n",
    "plt.gray()\n",
    "plt.subplot(2,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(img1)\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(img1.flatten(), 256, (0, 255))\n",
    "plt.subplot(2,2,3)\n",
    "plt.axis('off')\n",
    "plt.imshow(img2)\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(img2.flatten(), 256, (0, 255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a030c58775d405f5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "img = imread('images/pebbles.jpg') # 'pebbles.jpg' or 'schrift.png'\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "from skimage.filters import threshold_otsu\n",
    "thresh = threshold_otsu(img)\n",
    "segments = img > thresh\n",
    "# END SOLUTION\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.gray()\n",
    "plt.subplot(3,1,1); plt.axis('off'); plt.imshow(img)\n",
    "plt.subplot(3,1,2); plt.hist(img.flatten(), 256, (0,255))\n",
    "plt.axvline(thresh, color='r')\n",
    "plt.subplot(3,1,3); plt.axis('off'); plt.imshow(segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "seg-hist-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### c) Shading\n",
    "\n",
    "Shading may cause a problem to histogram based segmentation. In the lecture (CV-07 slide 13), it was proposed to compute a shading image to deal with that problem. Apply this approach to the images `schrift.png` and `pebbles.jpg`. You may use filter functions from scikit-image for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "seg-hist-a3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "img = imread('images/schrift.png').astype(float)/255\n",
    "#img = imread('images/pebbles.png').astype(float)/255\n",
    "\n",
    "## BEGIN SOLUTION\n",
    "from scipy.ndimage import maximum_filter, uniform_filter\n",
    "from skimage.filters import rank\n",
    "from skimage.morphology import disk\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.gray()\n",
    "plt.subplot(2,3,1); plt.axis('off'); plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,3,2); plt.axis('off')\n",
    "#img_bg = maximum_filter(img,13)\n",
    "img_bg = rank.maximum(rank.mean(img_as_ubyte(img), disk(5)), disk(13))/255.0\n",
    "#img_bg = maximum_filter(uniform_filter(img, 5), 13)\n",
    "plt.imshow(img_bg, vmin=0, vmax=1)\n",
    "\n",
    "img_corrected = img / img_bg\n",
    "img_corrected /= img_corrected.max()\n",
    "\n",
    "plt.subplot(2,3,3); plt.axis('off')\n",
    "plt.imshow(img_corrected)\n",
    "\n",
    "# show histograms\n",
    "plt.subplot(2,3,4); plt.hist(img.flatten(),256,(0,1))\n",
    "plt.subplot(2,3,5); plt.hist(img_corrected.flatten(),256,(0,1))\n",
    "\n",
    "# show result\n",
    "plt.subplot(2,3,6); plt.imshow(img_corrected > .5)\n",
    "plt.show()\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pyramid",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: Pyramid representation (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pyramid-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is the *Gaussian pyramid*? How does the **reduce** operation work? Explain in your own words what low pass filtering is and why it should be used when building the pyramid? Implement the **reduce** operation and generate a figure similar to the one on (CV-07 slide 32)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pyramid-a1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "A Gaussian pyramid is a multiscale representation, where the different scales are gained by applying Gaussian smoothing with different standard deviations $\\sigma$. Such a pyramid is usually divided in octaves, where one octave means doubling the parameter $\\sigma$. The most simple case, that is also depicted in (CV-07 slide 32), only uses the full octaves, while more general approaches also introduce intermediate levels in each octave. Applying the Gaussian kernel acts as a low pass filter, i.e. only low frequencies will be kept while higher frequencies are cut off. Hence at the higher octaves, no details of the image are left on only large structures will remain visible. Hence it is common practice, to also resize the images in such a pyramid at every octave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pyramid-impl1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "img = imread('images/mermaid.png')\n",
    "\n",
    "pyramid_image = img.copy() # change this!\n",
    "# BEGIN SOLUTION\n",
    "# create a 2D-kernel for smoothing\n",
    "kernel = (1 / 16) * np.array([[0.87,3.91,6.44,3.91,0.87]])\n",
    "kernel = kernel.T.dot(kernel)\n",
    "\n",
    "def reduce(img, kernel):\n",
    "    \"\"\"Smoothes and subsamples image resulting in image of half the size\n",
    "    \n",
    "    Args:\n",
    "        img (ndarray): Input image\n",
    "        kernel (ndarray): Smoothing kernel.\n",
    "    \n",
    "    Returngs:\n",
    "        img (ndarray): Input image reduced to half the size.\n",
    "    \"\"\"\n",
    "    # the reduce operation is a combination of smoothing ...\n",
    "    img = ndimage.convolve(img, kernel)\n",
    "    # ... and subsampling (resizing)\n",
    "    img = img[::2, ::2]\n",
    "    return img\n",
    "\n",
    "while min(img.shape) > 1:\n",
    "    img = reduce(img, kernel)\n",
    "    # now insert the resulting octave into the final image for visualization\n",
    "    pyramid_image[ img.shape[0] + 1, :img.shape[1] + 1] = 0\n",
    "    pyramid_image[:img.shape[0] + 1,  img.shape[1] + 1] = 0\n",
    "    pyramid_image[:img.shape[0],     :img.shape[1]    ] = img\n",
    "# END SOLUTION\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.gray()\n",
    "plt.imshow(pyramid_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pyramid-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is the **expand** operation? Why can the **reduce** operation not be inverted? Implement (not using the library function;-) the **expand** operation and generate an image similar to the one on (CV-07 slide 34).\n",
    "\n",
    "Remark: for producing the final image, do not start with the original image, but with a reduced version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pyramid-a2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The expand operation aims to reconstruct an image from an image at higher scale. While a perfect reconstruction would be possible in a continous setup, it is not possible with our reduce operation that subsamples at every octave and thereby looses information. When implementing the expand operation, one has to undo this subsampling. Although this is not possible, one can get a good approximation by using different formulae to compute pixels at even and odd coordinates: This yields for different cases: even/even, even/odd, odd/even, and odd/odd. The solution presents two different ways to deal with this situation: (1) `expand1()` uses four different 2D-kernels to compute the different cases. (2) `expand2()` uses two 1D-kernels and applies them twice, first vertically and then horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pyramid-impl2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "img = imread('images/mermaid.png')\n",
    "\n",
    "steps = 4\n",
    "pyramid_image = np.zeros((img.shape[0] + (2 ** steps), img.shape[1] + (2 ** steps)))\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "assert 'kernel' in globals(), \"You should run part b) before part c) to define reduce!\"\n",
    "\n",
    "# two 1D-kernels for expand:\n",
    "kernel1 = (1 / 8.28) * np.array([[0.87, 6.44, 0.87]])\n",
    "kernel2 = (1 / 7.82) * np.array([[3.91, 3.91]])\n",
    "\n",
    "\n",
    "def expand1(img, kernel1, kernel2):\n",
    "    \"\"\"Expands image using 2D kernels\n",
    "    \n",
    "    Args:\n",
    "        img (ndarray): Input image.\n",
    "        kernel1 (1d ndarray): First kernel.\n",
    "        kernel2 (1d ndarray): Second kernel.\n",
    "    \n",
    "    Returns:\n",
    "        result (ndarray): The expanded image.\n",
    "    \"\"\"\n",
    "    # the reduce operation has to distinguish even and odd columns/rows\n",
    "    result = np.empty((img.shape[0]*2,img.shape[1]*2))\n",
    "    result[ ::2,   ::2] = ndimage.convolve(img, kernel1.T.dot(kernel1))\n",
    "    result[ ::2,  1::2] = ndimage.convolve(img, kernel1.T.dot(kernel2))\n",
    "    result[1::2,   ::2] = ndimage.convolve(img, kernel2.T.dot(kernel1))\n",
    "    result[1::2,  1::2] = ndimage.convolve(img, kernel2.T.dot(kernel2))\n",
    "    return result\n",
    "\n",
    "# alternative implementation: \n",
    "def expand2(img, kernel1, kernel2):\n",
    "    \"\"\"Expands image using 1D kernels\n",
    "    \n",
    "    Args:\n",
    "        img (ndarray): Input image.\n",
    "        kernel1 (1d ndarray): First kernel.\n",
    "        kernel2 (1d ndarray): Second kernel.\n",
    "    \n",
    "    Returns:\n",
    "        result (ndarray): The expanded image.\n",
    "    \"\"\"\n",
    "    temp = np.empty((img.shape[0]*2, img.shape[1]))\n",
    "    temp[ ::2, :] = ndimage.convolve(img, kernel1.T)\n",
    "    temp[1::2, :] = ndimage.convolve(img, kernel2.T)\n",
    "\n",
    "    result = np.empty((temp.shape[0], temp.shape[1]*2))  \n",
    "    result[:,  ::2] = ndimage.convolve(temp, kernel1)\n",
    "    result[:, 1::2] = ndimage.convolve(temp, kernel2)\n",
    "    return result\n",
    "\n",
    "for _ in range(steps):\n",
    "    img = reduce(img, kernel)\n",
    "    \n",
    "pyramid_image[:img.shape[0], :img.shape[1]] = img\n",
    "for _ in range(steps):\n",
    "    img = expand1(img, kernel1, kernel2)\n",
    "    pyramid_image[((img.shape[0] // 2) + 1):img.shape[0], :img.shape[1]] = img[img.shape[0] // 2 + 1:, :]\n",
    "    pyramid_image[:img.shape[0], (img.shape[1] // 2 + 1):img.shape[1]] = img[:, img.shape[1] // 2 + 1:]\n",
    "\n",
    "# END SOLUTION\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.gray()\n",
    "plt.imshow(pyramid_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pyramid-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** What is the *Laplacian pyramid*? What is it used for? Compute the Laplacian pyramid and generate an image similar to the one on (CV-07 slide 36)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pyramid-a3",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The *Laplacian pyramid* is the difference between $g^i$ and $g^{i + 1 \\rightarrow i}$. It is used as a redundancy free representation of the second derivative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pyramid-impl3",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "img = imread('images/mermaid.png')\n",
    "\n",
    "pyramid_image = np.zeros(img.shape)\n",
    "# BEGIN SOLUTION\n",
    "assert 'kernel' in globals(), \"You should run part b) before part d) to define reduce!\"\n",
    "assert 'kernel1' in globals(), \"You should run part c) before part d) to define expand!\"\n",
    "\n",
    "while min(img.shape) > 1:\n",
    "    r = reduce(img,kernel)\n",
    "    e = expand1(r, kernel1,kernel2)\n",
    "    d = img - e[:img.shape[0], :img.shape[1]]\n",
    "    # Now insert the resulting octave into the final image for visualization.\n",
    "    pyramid_image[:d.shape[0],    :d.shape[1]] = d\n",
    "    pyramid_image[d.shape[0] - 1, :d.shape[1]-1] = d.min()\n",
    "    pyramid_image[:d.shape[0] - 1, d.shape[1]-1] = d.min()\n",
    "    img = r\n",
    "\n",
    "# END SOLUTION\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.gray()\n",
    "plt.imshow(pyramid_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "region-merging",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 4: Region merging (5 points)\n",
    "\n",
    "Implement the *region merging* algorithm (CV-07 slide 39) and apply it to the image `segments.png` (or some part of it). Use a simple *homogeneity condition*, e.g. that the maximal difference between gray values in a segment is not larger than a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "region-merging-impl",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v2 import imread\n",
    "\n",
    "\n",
    "img = imread('./images/segments.png')\n",
    "# Choosing a large image region lengthens computation time\n",
    "img = img[64:128,64:128]\n",
    "\n",
    "# compute the `label` array by implementing \"region merging\"\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# Initialize the region adjacency graph (RAG).\n",
    "# Such a graph consists of nodes and edges:\n",
    "#   - each node will be identifed by a unique label (integer number).\n",
    "#   - edges will be computed on the fly: neighboring pixel with different label will constitute an edge.\n",
    "# In the beginning, each pixel will be a segment, i.e. a node in the RAG:\n",
    "label = np.random.permutation(img.size).reshape(img.shape)\n",
    "print(\"Initialization from image with shape {}: {} segments (=pixels)\".format(img.shape, label.size))\n",
    "\n",
    "# We also introduce two auxiliary arrays to hold the minimum and maximum gray value in each region:\n",
    "minval = img.copy()\n",
    "maxval = img.copy()\n",
    "\n",
    "\n",
    "# Define a homgeneity criterion:\n",
    "# A region will be considered homogenous, if its minimal and maximal grayvalues do not differ more than\n",
    "# a given threshold.\n",
    "def homogenous(coords, threshold):\n",
    "    \"\"\"\n",
    "    Check if two regions, identified by two (neighboring) coordinate pairs, together fulfill the\n",
    "    homogeneity criterion.\n",
    "    \n",
    "    This function makes use of the global auxiliary arrays 'maxval' and 'minval'.\n",
    "    \n",
    "    Args: \n",
    "        coords (list): List of coordinate tuples.\n",
    "        threshold (float): Maximum allowed distance between min and max values at positions given in coords.\n",
    "        \n",
    "    Returns:\n",
    "        (bool): True, if homogenous; else false.\n",
    "    \"\"\"\n",
    "    return max(maxval[coords]) - min(minval[coords]) <= threshold\n",
    "\n",
    "\n",
    "def merge(coords):\n",
    "    \"\"\"\n",
    "    Merge two regions. The regions are identified by two coordinates, providing points in these regions.\n",
    "    This function will adapt the global array 'label' to reflect the merge. It will also update the\n",
    "    auxiliary arrays 'minval' and 'maxval' accordingly.\n",
    "    \n",
    "    Args:\n",
    "        coords (list): List of two coordinate tuples.\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get the labels for their regions to be merged.\n",
    "    l1, l2 = label[coords]\n",
    "    \n",
    "    # get the indices of all pixels belonging to the merged region\n",
    "    r = (label == l2) | (label == l1)\n",
    "    \n",
    "    # set all labels in the merged region to label l1\n",
    "    label[r] = l1\n",
    "    \n",
    "    # also update the auxiliary array.\n",
    "    minval[r] = min(minval[coords])\n",
    "    maxval[r] = max(maxval[coords])\n",
    "\n",
    "\n",
    "# Perform region merging: \n",
    "# At each iteration merge regions that fulfill the homogeneity condition for a given threshold\n",
    "# (max_diff = maximal difference between gray values in merged region)\n",
    "for max_diff in range(0, 80, 5):\n",
    "\n",
    "    # Horizontal:\n",
    "    for i in np.argwhere(label[:, :-1] != label[:, 1:]):\n",
    "    \n",
    "        coords = tuple(c for c in zip(i, i + (0, 1)))\n",
    "        if homogenous(coords, max_diff):\n",
    "            merge(coords)\n",
    "    print(\"After horizontal merge (threshold = {}): {} segments.\".format(max_diff,np.unique(label).size))\n",
    "\n",
    "    # Vertical:\n",
    "    for i in np.argwhere(label[:-1,:] != label[1:,:]):\n",
    "        coords = tuple(c for c in zip(i,i + (1,0)))\n",
    "        if homogenous(coords, max_diff):\n",
    "            merge(coords)\n",
    "    print(\"After vertical merge (threshold = {}): {} segments.\".format(max_diff,np.unique(label).size))\n",
    "\n",
    "# END SOLUTION\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.gray()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(label, cmap='prism')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
